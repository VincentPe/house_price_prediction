{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *\n",
    "from settings import *\n",
    "\n",
    "%store -r __RequiredPackages\n",
    "%store -r __JupyterOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "__RequiredPackages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "__JupyterOptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "data = pd.read_csv('train.csv')\n",
    "validation = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_testing_pipe(data, keep_features, target, NA_means_not_there_cols=NA_means_not_there_cols, \n",
    "                         cont_impute_cols=cont_impute_cols, cat_impute_cols=cat_impute_cols, \n",
    "                         dev_seed=dev_seed, new_session=False, new_features=False):\n",
    "    \"\"\"\n",
    "    Does all the preprocessing steps,\n",
    "    uses cross validation to test the performance of several models.\n",
    "    Used to quickly compare different sets of features\n",
    "    \n",
    "    Note: Make sure the indexes are in order without gaps\n",
    "    \"\"\"\n",
    "    # Transform features that dont create data leakage issues\n",
    "    if new_features | new_session:\n",
    "        data = standard_preprocessing_function(data, new_session, NA_means_not_there_cols)\n",
    "    \n",
    "    # Create different splits of train and test\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=dev_seed)\n",
    "    \n",
    "    # Initiate empty object for further analysis\n",
    "    pred_perf_dict = {'LinearRegression': [], 'KNeighborsRegressor': [], 'RandomForestRegressor': [],\n",
    "                      'GradientBoostingRegressor': [], 'SVR': []}\n",
    "    predictions_df = pd.DataFrame({'obs_nr': data.index})\n",
    "    cv_round = 0\n",
    "    \n",
    "    # Split features and target\n",
    "    X = data.drop(target, axis=1)\n",
    "    y = data[target]\n",
    "    \n",
    "    # Fit models while looping through the train/test-splits\n",
    "    for train_index, test_index in kf.split(X): \n",
    "        cv_round  += 1\n",
    "        \n",
    "        X_train, X_test = X.loc[train_index, :], X.loc[test_index, :]\n",
    "        y_train, y_test = y.values[train_index], y.values[test_index]\n",
    "        \n",
    "        # Prepare features based on target variable in testset\n",
    "        prepper = leakage_preventive_preprocessing_function(cont_impute_cols, cat_impute_cols, keep_features)\n",
    "        X_train = prepper.fit_transform(X_train, y_train)\n",
    "        X_test = prepper.transform(X_test)\n",
    "        \n",
    "        # Fit models\n",
    "        pred_perf_dict, predictions_df = fit_model('LinearRegression', X_train, y_train, X_test, y_test, test_index, \n",
    "                                                   pred_perf_dict, predictions_df, cv_round)\n",
    "        pred_perf_dict, predictions_df = fit_model('KNeighborsRegressor', X_train, y_train, X_test, y_test, test_index, \n",
    "                                                   pred_perf_dict, predictions_df, cv_round)\n",
    "        pred_perf_dict, predictions_df = fit_model('RandomForestRegressor', X_train, y_train, X_test, y_test, test_index, \n",
    "                                                   pred_perf_dict, predictions_df, cv_round)\n",
    "        pred_perf_dict, predictions_df = fit_model('GradientBoostingRegressor', X_train, y_train, X_test, y_test, test_index, \n",
    "                                                   pred_perf_dict, predictions_df, cv_round)\n",
    "        pred_perf_dict, predictions_df = fit_model('SVR', X_train, y_train, X_test, y_test, test_index, \n",
    "                                                   pred_perf_dict, predictions_df, cv_round)\n",
    "\n",
    "        #print('Completed predicting round {}'.format(cv_round))\n",
    "        \n",
    "    return pred_perf_dict, predictions_df\n",
    "        \n",
    "def fit_model(model_name, X_train, y_train, X_test, y_test, test_index, \n",
    "              pred_perf_dict, predictions_df, cv_round, n_jobs=n_jobs, dev_seed=dev_seed):\n",
    "    if model_name == 'LinearRegression':\n",
    "        model = LinearRegression(n_jobs=n_jobs).fit(X_train, y_train)\n",
    "    elif model_name == 'KNeighborsRegressor':  \n",
    "        model = neighbors.KNeighborsRegressor(n_neighbors = 7, n_jobs=n_jobs).fit(X_train, y_train)\n",
    "    elif model_name == 'RandomForestRegressor':\n",
    "        model = RandomForestRegressor(n_estimators=50, random_state=dev_seed, n_jobs=n_jobs).fit(X_train, y_train)\n",
    "    elif model_name == 'GradientBoostingRegressor':\n",
    "        model = GradientBoostingRegressor(random_state=dev_seed).fit(X_train, y_train)\n",
    "    elif model_name == 'SVR':\n",
    "        model = SVR(kernel = 'rbf').fit(X_train, y_train)\n",
    "    \n",
    "    preds = model.predict(X_test)\n",
    "    pred_perf_dict[model_name].append(sqrt(mean_squared_error(y_test, preds)))\n",
    "    temp_preds = pd.DataFrame({'obs_nr': test_index, model_name + str(cv_round): preds})\n",
    "    predictions_df = predictions_df.merge(temp_preds, how='left', on='obs_nr')\n",
    "    \n",
    "    return pred_perf_dict, predictions_df\n",
    "\n",
    "def show_performance(pred_perf_dict):\n",
    "    return pd.DataFrame(pd.DataFrame(pred_perf_dict).mean(axis=0), columns=['rmsle'])\n",
    "\n",
    "def standard_preprocessing_function(data, new_session, NA_means_not_there_cols, scale_cont_cols):\n",
    "    \"\"\"\n",
    "    Prepare the dataset across train and testset.\n",
    "    No data leakage issues at this stage\n",
    "    \"\"\"\n",
    "    # Replace salesprice with a log scaled version of it\n",
    "    data['LogSalePrice'] = np.log(data['SalePrice'])\n",
    "    # Use np.exp on predictions to scale back to actual sales price\n",
    "    \n",
    "    # Impute missing values where they are not at random\n",
    "    data[NA_means_not_there_cols] = data[NA_means_not_there_cols].fillna('Not_present') \n",
    "    data['LotFrontage'] = data['LotFrontage'].fillna(0)\n",
    "    \n",
    "    # Create binary features\n",
    "    data['AllBathsSum'] = np.sum(data[['BsmtHalfBath', 'HalfBath', 'BsmtFullBath', 'FullBath']], axis=1)\n",
    "    data['TotalSFInclBsmnt'] = np.sum(data[['TotalBsmtSF', '1stFlrSF', '2ndFlrSF']], axis=1)\n",
    "    data['YardArea'] = data['LotArea'] - data['1stFlrSF'] - data['GarageArea']\n",
    "    \n",
    "    # Make a more even distribution for continuous features as well\n",
    "    for col in [scale_cont_cols]:\n",
    "        data['Log' + col] = np.log1p(data[col])\n",
    "        \n",
    "    # Transform existing variables\n",
    "    data = replace_ordinal_values(data)\n",
    "    \n",
    "    # Remove outliers\n",
    "    data = data[data['LogTotalSFInclBsmnt'] < 8.9].reset_index(drop=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "class leakage_preventive_preprocessing_function():\n",
    "    \n",
    "    def __init__(self, cont_impute_cols, cat_impute_cols, mean_enc_cols, keep_features):\n",
    "        self.cont_impute_cols = cont_impute_cols\n",
    "        self.cat_impute_cols = cat_impute_cols\n",
    "        self.mean_enc_cols = mean_enc_cols\n",
    "        self.keep_features = keep_features\n",
    "        self.mean_enc_dict = {}\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Fit regression to impute NAs for GarageYrBlt\n",
    "        self.reg = LinearRegression().fit(X.loc[X['GarageYrBlt'].notna(), ['GarageYrBlt']], \n",
    "                                          y[X['GarageYrBlt'].notna()])\n",
    "        self.avg_houseprice_nogarage = np.mean(y[X['GarageYrBlt'].isna()])\n",
    "        self.garage_yearbuilt_impute = (self.avg_houseprice_nogarage - self.reg.intercept_) / self.reg.coef_[0]\n",
    "        \n",
    "        # Fit imputer to impute missing values\n",
    "        self.num_imputer = SimpleImputer(missing_values=np.nan, strategy='median').fit(X[self.cont_impute_cols])\n",
    "        self.cat_imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent').fit(X[self.cat_impute_cols])\n",
    "        \n",
    "        # Mean encode based on the current split\n",
    "        X[target] = y\n",
    "        for col in [self.mean_enc_cols]:\n",
    "            self.mean_enc_dict[col] = X.groupby(col)[target].mean()\n",
    "        X = X.drop([target], axis=1)\n",
    "        \n",
    "        # Save mean of target when ME's could not be created due to specific split\n",
    "        self.target_mean = np.mean(y)\n",
    "        \n",
    "        # Transform mean encodings for standard scaler \n",
    "        for col in [self.mean_enc_cols]:\n",
    "            X['ME_' + col] = X[col].map(self.mean_enc_dict[col])\n",
    "            \n",
    "            # Median impute NA's for the encoding\n",
    "            X.loc[X['ME_' + col].isnull(), 'ME_' + col] = self.target_mean\n",
    "        \n",
    "        self.standardscaler = preprocessing.StandardScaler().fit(X[keep_features])\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # Impute missing values based on specific strategy\n",
    "        X.loc[X['GarageYrBlt'].isna(), 'GarageYrBlt'] = self.garage_yearbuilt_impute\n",
    "        \n",
    "        # Use imputer to impute missing values\n",
    "        X[self.cont_impute_cols] = self.num_imputer.transform(X[self.cont_impute_cols])\n",
    "        X[self.cat_impute_cols] = self.cat_imputer.transform(X[self.cat_impute_cols])\n",
    "        \n",
    "        # Transform mean encodings\n",
    "        for col in [self.mean_enc_cols]:\n",
    "            X['ME_' + col] = X[col].map(self.mean_enc_dict[col])\n",
    "            \n",
    "            # Median impute NA's for the encoding\n",
    "            X.loc[X['ME_' + col].isnull(), 'ME_' + col] = self.target_mean\n",
    "\n",
    "        X[keep_features] = self.standardscaler.transform(X[keep_features])\n",
    "        \n",
    "        return X[keep_features]\n",
    "    \n",
    "    def fit_transform(self, X, y):\n",
    "        self.fit(X, y)\n",
    "        X = self.transform(X)\n",
    "        return X\n",
    "    \n",
    "def replace_ordinal_values(X):\n",
    "    \"\"\"\n",
    "    Check whether any numerical variables are actually categorical and vice versa\n",
    "    \"\"\"\n",
    "    clean_up_dict = {\n",
    "        # Categorical to numerical\n",
    "                    \"LotShape\": {'IR3': 0, 'IR2': 1, 'IR1': 2, 'Reg': 3},\n",
    "                    \"LandSlope\": {\"Gtl\": 2, \"Mod\": 1, \"Sev\": 0},\n",
    "                    \"ExterQual\": {\"Ex\": 4, \"Gd\": 3, \"TA\": 2, \"Fa\": 1, \"Po\": 0},\n",
    "                    \"ExterCond\": {\"Ex\": 4, \"Gd\": 3, \"TA\": 2, \"Fa\": 1, \"Po\": 0},\n",
    "                    \"BsmtQual\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"Not_present\": 0},\n",
    "                    \"BsmtCond\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"Not_present\": 0},\n",
    "                    \"BsmtExposure\": {\"Gd\": 4, \"Av\": 3, \"Mn\": 2, \"No\": 1, \"Not_present\": 0},\n",
    "                    \"BsmtFinType1\": {\"GLQ\": 6, \"ALQ\": 5, \"BLQ\": 4, \"Rec\": 3, \"LwQ\": 2, \"Unf\": 1, \"Not_present\": 0},\n",
    "                    \"BsmtFinType2\": {\"GLQ\": 6, \"ALQ\": 5, \"BLQ\": 4, \"Rec\": 3, \"LwQ\": 2, \"Unf\": 1, \"Not_present\": 0},\n",
    "                    \"HeatingQC\": {\"Ex\": 4, \"Gd\": 3, \"TA\": 2, \"Fa\": 1, \"Po\": 0},\n",
    "                    \"CentralAir\": {\"Y\": 1, \"N\": 0},\n",
    "                    \"KitchenQual\": {\"Ex\": 4, \"Gd\": 3, \"TA\": 2, \"Fa\": 1, \"Po\": 0},\n",
    "                    \"Functional\": {\"Typ\": 7, \"Min1\": 6, \"Min2\": 5, \"Mod\": 4, \"Maj1\": 3, \"Maj2\": 2, \"Sev\": 1, \"Sal\": 0},\n",
    "                    \"FireplaceQu\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"Not_present\": 0},\n",
    "                    \"GarageFinish\": {\"Fin\": 3, \"RFn\": 2, \"Unf\": 1, \"Not_present\": 0},\n",
    "                    \"GarageQual\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"Not_present\": 0},\n",
    "                    \"GarageCond\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"Not_present\": 0},\n",
    "                    \"PavedDrive\": {\"Y\": 2, \"P\": 1, \"N\": 0},\n",
    "                    \"PoolQC\": {\"Ex\": 4, \"Gd\": 3, \"TA\": 2, \"Fa\": 1, \"Not_present\": 0},\n",
    "                    \"Fence\": {\"GdPrv\": 4, \"MnPrv\": 3, \"GdWo\": 2, \"MnWw\": 1, \"Not_present\": 0},\n",
    "        # Numerical to categorical\n",
    "                    \"MSSubClass\": {20: \"A\", 30: \"B\", 40: \"C\", 45: \"D\", 50: \"E\", 60: \"F\", 70: \"G\", 75: \"H\",\n",
    "                                   80: \"I\", 85: \"J\", 90: \"K\", 120: \"L\", 150: \"M\", 160: \"N\", 180: \"O\", 190: \"P\"}\n",
    "    }\n",
    "    X.replace(clean_up_dict, inplace=True)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1095, 365, 1095, 365)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divide the actual train in train and test\n",
    "X = data.drop(['SalePrice', 'LogSalePrice'], axis=1)\n",
    "y = data['LogSalePrice']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testset_size, random_state=dev_seed)\n",
    "\n",
    "len(X_train), len(X_test), len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = standard_preprocessing_function(X_train, NA_means_not_there_cols)\n",
    "X_test = standard_preprocessing_function(X_test, NA_means_not_there_cols)\n",
    "X_validation = standard_preprocessing_function(X_validation, NA_means_not_there_cols)\n",
    "\n",
    "prepper = leakage_preventive_preprocessing_function(cont_impute_cols, cat_impute_cols)\n",
    "X_train = prepper.fit_transform(X_train, y_train)\n",
    "X_test = prepper.transform(X_test)\n",
    "validation = prepper.transform(validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_up_dict = {\n",
    "    # Categorical to numerical\n",
    "                \"LotShape\": {'IR3': 0, 'IR2': 1, 'IR1': 2, 'Reg': 3},\n",
    "                \"LandSlope\": {\"Gtl\": 2, \"Mod\": 1, \"Sev\": 0},\n",
    "                \"ExterQual\": {\"Ex\": 4, \"Gd\": 3, \"TA\": 2, \"Fa\": 1, \"Po\": 0},\n",
    "                \"ExterCond\": {\"Ex\": 4, \"Gd\": 3, \"TA\": 2, \"Fa\": 1, \"Po\": 0},\n",
    "                \"BsmtQual\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"Not_present\": 0},\n",
    "                \"BsmtCond\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"Not_present\": 0},\n",
    "                \"BsmtExposure\": {\"Gd\": 4, \"Av\": 3, \"Mn\": 2, \"No\": 1, \"Not_present\": 0},\n",
    "                \"BsmtFinType1\": {\"GLQ\": 6, \"ALQ\": 5, \"BLQ\": 4, \"Rec\": 3, \"LwQ\": 2, \"Unf\": 1, \"Not_present\": 0},\n",
    "                \"BsmtFinType2\": {\"GLQ\": 6, \"ALQ\": 5, \"BLQ\": 4, \"Rec\": 3, \"LwQ\": 2, \"Unf\": 1, \"Not_present\": 0},\n",
    "                \"HeatingQC\": {\"Ex\": 4, \"Gd\": 3, \"TA\": 2, \"Fa\": 1, \"Po\": 0},\n",
    "                \"CentralAir\": {\"Y\": 1, \"N\": 0},\n",
    "                \"KitchenQual\": {\"Ex\": 4, \"Gd\": 3, \"TA\": 2, \"Fa\": 1, \"Po\": 0},\n",
    "                \"Functional\": {\"Typ\": 7, \"Min1\": 6, \"Min2\": 5, \"Mod\": 4, \"Maj1\": 3, \"Maj2\": 2, \"Sev\": 1, \"Sal\": 0},\n",
    "                \"FireplaceQu\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"Not_present\": 0},\n",
    "                \"GarageFinish\": {\"Fin\": 3, \"RFn\": 2, \"Unf\": 1, \"Not_present\": 0},\n",
    "                \"GarageQual\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"Not_present\": 0},\n",
    "                \"GarageCond\": {\"Ex\": 5, \"Gd\": 4, \"TA\": 3, \"Fa\": 2, \"Po\": 1, \"Not_present\": 0},\n",
    "                \"PavedDrive\": {\"Y\": 2, \"P\": 1, \"N\": 0},\n",
    "                \"PoolQC\": {\"Ex\": 4, \"Gd\": 3, \"TA\": 2, \"Fa\": 1, \"Not_present\": 0},\n",
    "                \"Fence\": {\"GdPrv\": 4, \"MnPrv\": 3, \"GdWo\": 2, \"MnWw\": 1, \"Not_present\": 0},\n",
    "    # Numerical to categorical\n",
    "                \"MSSubClass\": {20: \"A\", 30: \"B\", 40: \"C\", 45: \"D\", 50: \"E\", 60: \"F\", 70: \"G\", 75: \"H\",\n",
    "                               80: \"I\", 85: \"J\", 90: \"K\", 120: \"L\", 150: \"M\", 160: \"N\", 180: \"O\", 190: \"P\"}\n",
    "}\n",
    "data.replace(clean_up_dict, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('prep_train.csv', index=False)\n",
    "validation.to_csv('prep_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hpp_venv",
   "language": "python",
   "name": "hpp_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
